{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-27T21:26:01.604885700Z",
     "start_time": "2024-06-27T21:26:01.586926Z"
    },
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "from langchain_openai import ChatOpenAI, OpenAI\n",
    "from langchain.chains import create_sql_query_chain\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bf75e1f",
   "metadata": {},
   "source": [
    "# [Build a Question/Answering system over SQL data](https://python.langchain.com/v0.2/docs/tutorials/sql_qa/)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5944bd23",
   "metadata": {},
   "source": [
    "## Architecture\n",
    "\n",
    "At a high-level, the steps of these systems are:  \n",
    "\n",
    "Convert question to DSL query: Model converts user input to a SQL query.  \n",
    "Execute SQL query: Execute the query.  \n",
    "Answer the question: Model responds to user input using the query results.  \n",
    "\n",
    "<img src='./assets/imgs/sql.bmp' ></img>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b7c3a870",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "150"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create sqlite\n",
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "engine = create_engine('sqlite:///iris.db', echo=False)\n",
    "\n",
    "df = pd.read_csv('./data/iris.csv')\n",
    "df.to_sql(name='iris', con=engine, if_exists='replace')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b8ff8f2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sqlite\n",
      "['iris']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"[(0, 5.1, 3.5, 1.4, 0.2, 'Setosa'), (1, 4.9, 3.0, 1.4, 0.2, 'Setosa'), (2, 4.7, 3.2, 1.3, 0.2, 'Setosa'), (3, 4.6, 3.1, 1.5, 0.2, 'Setosa'), (4, 5.0, 3.6, 1.4, 0.2, 'Setosa'), (5, 5.4, 3.9, 1.7, 0.4, 'Setosa'), (6, 4.6, 3.4, 1.4, 0.3, 'Setosa'), (7, 5.0, 3.4, 1.5, 0.2, 'Setosa'), (8, 4.4, 2.9, 1.4, 0.2, 'Setosa'), (9, 4.9, 3.1, 1.5, 0.1, 'Setosa')]\""
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_community.utilities import SQLDatabase\n",
    "\n",
    "db = SQLDatabase.from_uri(\"sqlite:///iris.db\")\n",
    "print(db.dialect)\n",
    "print(db.get_usable_table_names())\n",
    "db.run(\"SELECT * FROM iris LIMIT 10;\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c20c82d",
   "metadata": {},
   "source": [
    "### Convert question to SQL query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d23de1cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'SELECT variety, AVG(\"petal.length\") AS avg_petal_length, AVG(\"petal.width\") AS avg_petal_width\\nFROM iris\\nGROUP BY variety\\nORDER BY avg_petal_length DESC;'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm = ChatOpenAI()\n",
    "\n",
    "chain = create_sql_query_chain(llm, db)\n",
    "response = chain.invoke({\"question\": \"Qual a média das petalas por tipo de flor\"})\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "44a21bf5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'O langchain não está adapdado a esse modelo\\n'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Rodar com o gpt-40-mini \n",
    "\"\"\"O langchain não está adapdado a esse modelo\n",
    "\"\"\"\n",
    "# from langchain.schema.runnable import RunnableLambda\n",
    "# llm = ChatOpenAI(model='gpt-4o-mini', temperature=0) # o gpt-4o-mini Adiciona um subtipo\n",
    "\n",
    "\n",
    "# write_query = create_sql_query_chain(llm, db)\n",
    "# chain = write_query | RunnableLambda(lambda x: x[10:]) # Necessário adptar a saída\n",
    "# response = chain.invoke({\"question\": \"Qual a média de comprimento e largura das petalas por tipo de flor, remover limite\"})\n",
    "# response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cc09e71",
   "metadata": {},
   "source": [
    "We can execute the query to make sure it's valid:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e21e85ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"[('Virginica', 5.552, 2.026), ('Versicolor', 4.26, 1.3259999999999998), ('Setosa', 1.4620000000000002, 0.2459999999999999)]\""
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db.run(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16deefeb",
   "metadata": {},
   "source": [
    "This technique is inspired by papers like this, which suggest showing examples rows and being explicit about tables improves performance. We can also inspect the full prompt like so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "72d6ad55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are a SQLite expert. Given an input question, first create a syntactically correct SQLite query to run, then look at the results of the query and return the answer to the input question.\n",
      "Unless the user specifies in the question a specific number of examples to obtain, query for at most 5 results using the LIMIT clause as per SQLite. You can order the results to return the most informative data in the database.\n",
      "Never query for all columns from a table. You must query only the columns that are needed to answer the question. Wrap each column name in double quotes (\") to denote them as delimited identifiers.\n",
      "Pay attention to use only the column names you can see in the tables below. Be careful to not query for columns that do not exist. Also, pay attention to which column is in which table.\n",
      "Pay attention to use date('now') function to get the current date, if the question involves \"today\".\n",
      "\n",
      "Use the following format:\n",
      "\n",
      "Question: Question here\n",
      "SQLQuery: SQL Query to run\n",
      "SQLResult: Result of the SQLQuery\n",
      "Answer: Final answer here\n",
      "\n",
      "Only use the following tables:\n",
      "\u001b[33;1m\u001b[1;3m{table_info}\u001b[0m\n",
      "\n",
      "Question: \u001b[33;1m\u001b[1;3m{input}\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "chain.get_prompts()[0].pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c966076",
   "metadata": {},
   "source": [
    "### Execute SQL query\n",
    "Now that we've generated a SQL query, we'll want to execute it. This is the most dangerous part of creating a SQL chain. Consider carefully if it is OK to run automated queries over your data. Minimize the database connection permissions as much as possible. Consider adding a human approval step to you chains before query execution (see below)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cab64b0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"[('Virginica', 5.552, 2.026), ('Versicolor', 4.26, 1.3259999999999998), ('Setosa', 1.4620000000000002, 0.2459999999999999)]\""
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_community.tools.sql_database.tool import QuerySQLDataBaseTool\n",
    "\n",
    "execute_query = QuerySQLDataBaseTool(db=db)\n",
    "write_query = create_sql_query_chain(llm, db)\n",
    "chain = write_query | execute_query\n",
    "chain.invoke({\"question\": \"Qual a média das petalas por tipo de flor\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aa40aeb",
   "metadata": {},
   "source": [
    "## Answer the question\n",
    "\n",
    "Now that we've got a way to automatically generate and execute queries, we just need to combine the original question and SQL query result to generate a final answer. We can do this by passing question and result to the LLM once more:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bf69163e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A média das pétalas por tipo de flor é a seguinte:\n",
      "\n",
      "- Para a variedade 'Setosa', a média do comprimento da pétala é de aproximadamente 1.462 e a média da largura da pétala é de aproximadamente 0.246.\n",
      "- Para a variedade 'Versicolor', a média do comprimento da pétala é de 4.26 e a média da largura da pétala é de aproximadamente 1.326.\n",
      "- Para a variedade 'Virginica', a média do comprimento da pétala é de 5.552 e a média da largura da pétala é de aproximadamente 2.026.\n"
     ]
    }
   ],
   "source": [
    "from operator import itemgetter\n",
    "\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "\n",
    "answer_prompt = PromptTemplate.from_template(\n",
    "    \"\"\"Given the following user question, corresponding SQL query, and SQL result, answer the user question.\n",
    "\n",
    "Question: {question}\n",
    "SQL Query: {query}\n",
    "SQL Result: {result}\n",
    "Answer: \"\"\"\n",
    ")\n",
    "\n",
    "chain = (\n",
    "    RunnablePassthrough.assign(query=write_query).assign(\n",
    "        result=itemgetter(\"query\") | execute_query\n",
    "    )\n",
    "    | answer_prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "print(chain.invoke({\"question\": \"Qual a média das petalas por tipo de flor\"}))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "785135e3",
   "metadata": {},
   "source": [
    "## Agentes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2c3c4c4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new SQL Agent Executor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `sql_db_list_tables` with `{}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[38;5;200m\u001b[1;3miris\u001b[0m\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `sql_db_schema` with `{'table_names': 'iris'}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[33;1m\u001b[1;3m\n",
      "CREATE TABLE iris (\n",
      "\t\"index\" BIGINT, \n",
      "\t\"sepal.length\" FLOAT, \n",
      "\t\"sepal.width\" FLOAT, \n",
      "\t\"petal.length\" FLOAT, \n",
      "\t\"petal.width\" FLOAT, \n",
      "\tvariety TEXT\n",
      ")\n",
      "\n",
      "/*\n",
      "3 rows from iris table:\n",
      "index\tsepal.length\tsepal.width\tpetal.length\tpetal.width\tvariety\n",
      "0\t5.1\t3.5\t1.4\t0.2\tSetosa\n",
      "1\t4.9\t3.0\t1.4\t0.2\tSetosa\n",
      "2\t4.7\t3.2\t1.3\t0.2\tSetosa\n",
      "*/\u001b[0m\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `sql_db_query_checker` with `{'query': 'SELECT variety, AVG(petal.length) as average_petal_length FROM iris GROUP BY variety'}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3m```sql\n",
      "SELECT variety, AVG(petal_length) as average_petal_length FROM iris GROUP BY variety\n",
      "```\u001b[0m\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `sql_db_query` with `{'query': 'SELECT variety, AVG(petal.length) as average_petal_length FROM iris GROUP BY variety'}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3mError: (sqlite3.OperationalError) no such column: petal.length\n",
      "[SQL: SELECT variety, AVG(petal.length) as average_petal_length FROM iris GROUP BY variety]\n",
      "(Background on this error at: https://sqlalche.me/e/20/e3q8)\u001b[0m\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `sql_db_query_checker` with `{'query': 'SELECT variety, AVG(petal.width) as average_petal_length FROM iris GROUP BY variety'}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3m```sql\n",
      "SELECT variety, AVG(petal.width) as average_petal_width FROM iris GROUP BY variety\n",
      "```\u001b[0m\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `sql_db_query` with `{'query': 'SELECT variety, AVG(petal.length) as average_petal_length FROM iris GROUP BY variety'}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3mError: (sqlite3.OperationalError) no such column: petal.length\n",
      "[SQL: SELECT variety, AVG(petal.length) as average_petal_length FROM iris GROUP BY variety]\n",
      "(Background on this error at: https://sqlalche.me/e/20/e3q8)\u001b[0m\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `sql_db_query_checker` with `{'query': 'SELECT variety, AVG(\"petal.length\") as average_petal_length FROM iris GROUP BY variety'}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3m```sql\n",
      "SELECT variety, AVG(\"petal.length\") as average_petal_length FROM iris GROUP BY variety\n",
      "```\u001b[0m\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `sql_db_query` with `{'query': 'SELECT variety, AVG(\"petal.length\") as average_petal_length FROM iris GROUP BY variety'}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3m[('Setosa', 1.4620000000000002), ('Versicolor', 4.26), ('Virginica', 5.552)]\u001b[0m\u001b[32;1m\u001b[1;3mA média do comprimento das pétalas por tipo de flor é a seguinte:\n",
      "\n",
      "- Setosa: 1.46\n",
      "- Versicolor: 4.26\n",
      "- Virginica: 5.55\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'Qual a média das petalas por tipo de flor, usar todos os registros',\n",
       " 'output': 'A média do comprimento das pétalas por tipo de flor é a seguinte:\\n\\n- Setosa: 1.46\\n- Versicolor: 4.26\\n- Virginica: 5.55'}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_community.agent_toolkits import create_sql_agent\n",
    "\n",
    "llm = ChatOpenAI(model='gpt-4o-mini', temperature=0) \n",
    "agent_executor = create_sql_agent(llm, db=db, agent_type=\"openai-tools\", verbose=True)\n",
    "agent_executor.invoke({\"input\": \"Qual a média das petalas por tipo de flor, usar todos os registros\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0f674891",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[QuerySQLDataBaseTool(description=\"Input to this tool is a detailed and correct SQL query, output is a result from the database. If the query is not correct, an error message will be returned. If an error is returned, rewrite the query, check the query, and try again. If you encounter an issue with Unknown column 'xxxx' in 'field list', use sql_db_schema to query the correct table fields.\", db=<langchain_community.utilities.sql_database.SQLDatabase object at 0x7f78bcd75bb0>),\n",
       " InfoSQLDatabaseTool(description='Input to this tool is a comma-separated list of tables, output is the schema and sample rows for those tables. Be sure that the tables actually exist by calling sql_db_list_tables first! Example Input: table1, table2, table3', db=<langchain_community.utilities.sql_database.SQLDatabase object at 0x7f78bcd75bb0>),\n",
       " ListSQLDatabaseTool(db=<langchain_community.utilities.sql_database.SQLDatabase object at 0x7f78bcd75bb0>),\n",
       " QuerySQLCheckerTool(description='Use this tool to double check if your query is correct before executing it. Always use this tool before executing a query with sql_db_query!', db=<langchain_community.utilities.sql_database.SQLDatabase object at 0x7f78bcd75bb0>, llm=ChatOpenAI(client=<openai.resources.chat.completions.Completions object at 0x7f78bca59f40>, async_client=<openai.resources.chat.completions.AsyncCompletions object at 0x7f78bca096a0>, model_name='gpt-4o-mini', temperature=0.0, openai_api_key=SecretStr('**********'), openai_proxy=''), llm_chain=LLMChain(prompt=PromptTemplate(input_variables=['dialect', 'query'], template='\\n{query}\\nDouble check the {dialect} query above for common mistakes, including:\\n- Using NOT IN with NULL values\\n- Using UNION when UNION ALL should have been used\\n- Using BETWEEN for exclusive ranges\\n- Data type mismatch in predicates\\n- Properly quoting identifiers\\n- Using the correct number of arguments for functions\\n- Casting to the correct data type\\n- Using the proper columns for joins\\n\\nIf there are any of the above mistakes, rewrite the query. If there are no mistakes, just reproduce the original query.\\n\\nOutput the final SQL query only.\\n\\nSQL Query: '), llm=ChatOpenAI(client=<openai.resources.chat.completions.Completions object at 0x7f78bca59f40>, async_client=<openai.resources.chat.completions.AsyncCompletions object at 0x7f78bca096a0>, model_name='gpt-4o-mini', temperature=0.0, openai_api_key=SecretStr('**********'), openai_proxy='')))]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_community.agent_toolkits import SQLDatabaseToolkit\n",
    "\n",
    "toolkit = SQLDatabaseToolkit(db=db, llm=llm)\n",
    "\n",
    "tools = toolkit.get_tools()\n",
    "\n",
    "tools"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50076141",
   "metadata": {},
   "source": [
    "We will also want to create a system prompt for our agent. This will consist of instructions for how to behave."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e8f8b346",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import SystemMessage\n",
    "\n",
    "SQL_PREFIX = \"\"\"You are an agent designed to interact with a SQL database.\n",
    "Given an input question, create a syntactically correct SQLite query to run, then look at the results of the query and return the answer.\n",
    "Unless the user specifies a specific number of examples they wish to obtain, always limit your query to at most 5 results.\n",
    "You can order the results by a relevant column to return the most interesting examples in the database.\n",
    "Never query for all the columns from a specific table, only ask for the relevant columns given the question.\n",
    "You have access to tools for interacting with the database.\n",
    "Only use the below tools. Only use the information returned by the below tools to construct your final answer.\n",
    "You MUST double check your query before executing it. If you get an error while executing a query, rewrite the query and try again.\n",
    "\n",
    "DO NOT make any DML statements (INSERT, UPDATE, DELETE, DROP etc.) to the database.\n",
    "\n",
    "To start you should ALWAYS look at the tables in the database to see what you can query.\n",
    "Do NOT skip this step.\n",
    "Then you should query the schema of the most relevant tables.\"\"\"\n",
    "\n",
    "system_message = SystemMessage(content=SQL_PREFIX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c220472d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "from langgraph.prebuilt import create_react_agent\n",
    "\n",
    "agent_executor = create_react_agent(llm, tools, state_modifier=system_message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c187aa1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'agent': {'messages': [AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_JFJ48eFb06aygmMpjjAVsSCv', 'function': {'arguments': '{}', 'name': 'sql_db_list_tables'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 12, 'prompt_tokens': 556, 'total_tokens': 568}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_611b667b19', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-e7fd90e9-c254-4dd9-bdc1-07a33feb2478-0', tool_calls=[{'name': 'sql_db_list_tables', 'args': {}, 'id': 'call_JFJ48eFb06aygmMpjjAVsSCv', 'type': 'tool_call'}], usage_metadata={'input_tokens': 556, 'output_tokens': 12, 'total_tokens': 568})]}}\n",
      "----\n",
      "{'tools': {'messages': [ToolMessage(content='iris', name='sql_db_list_tables', tool_call_id='call_JFJ48eFb06aygmMpjjAVsSCv')]}}\n",
      "----\n",
      "{'agent': {'messages': [AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_I4xclNEAAoTI31GWrxwTGTtE', 'function': {'arguments': '{\"table_names\":\"iris\"}', 'name': 'sql_db_schema'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 16, 'prompt_tokens': 579, 'total_tokens': 595}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_0f03d4f0ee', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-19b692d7-4f48-446f-991c-a65d1aebf884-0', tool_calls=[{'name': 'sql_db_schema', 'args': {'table_names': 'iris'}, 'id': 'call_I4xclNEAAoTI31GWrxwTGTtE', 'type': 'tool_call'}], usage_metadata={'input_tokens': 579, 'output_tokens': 16, 'total_tokens': 595})]}}\n",
      "----\n",
      "{'tools': {'messages': [ToolMessage(content='\\nCREATE TABLE iris (\\n\\t\"index\" BIGINT, \\n\\t\"sepal.length\" FLOAT, \\n\\t\"sepal.width\" FLOAT, \\n\\t\"petal.length\" FLOAT, \\n\\t\"petal.width\" FLOAT, \\n\\tvariety TEXT\\n)\\n\\n/*\\n3 rows from iris table:\\nindex\\tsepal.length\\tsepal.width\\tpetal.length\\tpetal.width\\tvariety\\n0\\t5.1\\t3.5\\t1.4\\t0.2\\tSetosa\\n1\\t4.9\\t3.0\\t1.4\\t0.2\\tSetosa\\n2\\t4.7\\t3.2\\t1.3\\t0.2\\tSetosa\\n*/', name='sql_db_schema', tool_call_id='call_I4xclNEAAoTI31GWrxwTGTtE')]}}\n",
      "----\n",
      "{'agent': {'messages': [AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_Maqk0Vdo8EeuVPGWycpCUg6p', 'function': {'arguments': '{\"query\":\"SELECT variety, AVG(petal.length) AS average_petal_length FROM iris GROUP BY variety\"}', 'name': 'sql_db_query_checker'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 33, 'prompt_tokens': 742, 'total_tokens': 775}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_0f03d4f0ee', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-a80dbe71-04a9-4836-8acd-b18ae223cceb-0', tool_calls=[{'name': 'sql_db_query_checker', 'args': {'query': 'SELECT variety, AVG(petal.length) AS average_petal_length FROM iris GROUP BY variety'}, 'id': 'call_Maqk0Vdo8EeuVPGWycpCUg6p', 'type': 'tool_call'}], usage_metadata={'input_tokens': 742, 'output_tokens': 33, 'total_tokens': 775})]}}\n",
      "----\n",
      "{'tools': {'messages': [ToolMessage(content='```sql\\nSELECT variety, AVG(petal.length) AS average_petal_length FROM iris GROUP BY variety\\n```', name='sql_db_query_checker', tool_call_id='call_Maqk0Vdo8EeuVPGWycpCUg6p')]}}\n",
      "----\n",
      "{'agent': {'messages': [AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_7NTRHIqpfo4aywQ3IAIzec31', 'function': {'arguments': '{\"query\":\"SELECT variety, AVG(petal.length) AS average_petal_length FROM iris GROUP BY variety\"}', 'name': 'sql_db_query'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 32, 'prompt_tokens': 808, 'total_tokens': 840}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_0f03d4f0ee', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-4008c50f-d978-4730-b332-39ee873b215b-0', tool_calls=[{'name': 'sql_db_query', 'args': {'query': 'SELECT variety, AVG(petal.length) AS average_petal_length FROM iris GROUP BY variety'}, 'id': 'call_7NTRHIqpfo4aywQ3IAIzec31', 'type': 'tool_call'}], usage_metadata={'input_tokens': 808, 'output_tokens': 32, 'total_tokens': 840})]}}\n",
      "----\n",
      "{'tools': {'messages': [ToolMessage(content='Error: (sqlite3.OperationalError) no such column: petal.length\\n[SQL: SELECT variety, AVG(petal.length) AS average_petal_length FROM iris GROUP BY variety]\\n(Background on this error at: https://sqlalche.me/e/20/e3q8)', name='sql_db_query', tool_call_id='call_7NTRHIqpfo4aywQ3IAIzec31')]}}\n",
      "----\n",
      "{'agent': {'messages': [AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_YlApCY4v7a2ELtb7pUmKwpgG', 'function': {'arguments': '{\"query\":\"SELECT variety, AVG(`petal.length`) AS average_petal_length FROM iris GROUP BY variety\"}', 'name': 'sql_db_query_checker'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 34, 'prompt_tokens': 909, 'total_tokens': 943}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_0f03d4f0ee', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-9f11a19c-564b-4d38-9802-9ed933dd41d2-0', tool_calls=[{'name': 'sql_db_query_checker', 'args': {'query': 'SELECT variety, AVG(`petal.length`) AS average_petal_length FROM iris GROUP BY variety'}, 'id': 'call_YlApCY4v7a2ELtb7pUmKwpgG', 'type': 'tool_call'}], usage_metadata={'input_tokens': 909, 'output_tokens': 34, 'total_tokens': 943})]}}\n",
      "----\n",
      "{'tools': {'messages': [ToolMessage(content='```sql\\nSELECT variety, AVG(`petal.length`) AS average_petal_length FROM iris GROUP BY variety\\n```', name='sql_db_query_checker', tool_call_id='call_YlApCY4v7a2ELtb7pUmKwpgG')]}}\n",
      "----\n",
      "{'agent': {'messages': [AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_Ai13KLWTScrPCo4K5CSkbY1I', 'function': {'arguments': '{\"query\":\"SELECT variety, AVG(`petal.length`) AS average_petal_length FROM iris GROUP BY variety\"}', 'name': 'sql_db_query'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 33, 'prompt_tokens': 977, 'total_tokens': 1010}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_0f03d4f0ee', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-aaf92ca4-fd75-4571-a3c0-3675252523c4-0', tool_calls=[{'name': 'sql_db_query', 'args': {'query': 'SELECT variety, AVG(`petal.length`) AS average_petal_length FROM iris GROUP BY variety'}, 'id': 'call_Ai13KLWTScrPCo4K5CSkbY1I', 'type': 'tool_call'}], usage_metadata={'input_tokens': 977, 'output_tokens': 33, 'total_tokens': 1010})]}}\n",
      "----\n",
      "{'tools': {'messages': [ToolMessage(content=\"[('Setosa', 1.4620000000000002), ('Versicolor', 4.26), ('Virginica', 5.552)]\", name='sql_db_query', tool_call_id='call_Ai13KLWTScrPCo4K5CSkbY1I')]}}\n",
      "----\n",
      "{'agent': {'messages': [AIMessage(content='A média do comprimento das pétalas por tipo de flor é a seguinte:\\n\\n- **Setosa**: 1.46\\n- **Versicolor**: 4.26\\n- **Virginica**: 5.55', response_metadata={'token_usage': {'completion_tokens': 48, 'prompt_tokens': 1052, 'total_tokens': 1100}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_0f03d4f0ee', 'finish_reason': 'stop', 'logprobs': None}, id='run-72cfcb92-1efc-4216-a213-645d84110de3-0', usage_metadata={'input_tokens': 1052, 'output_tokens': 48, 'total_tokens': 1100})]}}\n",
      "----\n"
     ]
    }
   ],
   "source": [
    "for s in agent_executor.stream(\n",
    "    {\"messages\": [HumanMessage(content=\"Qual a média das petalas por tipo de flor, usar todos os registros\")]}\n",
    "):\n",
    "    print(s)\n",
    "    print(\"----\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
