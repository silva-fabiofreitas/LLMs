{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-27T21:26:01.604885700Z",
     "start_time": "2024-06-27T21:26:01.586926Z"
    },
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "#https://python.langchain.com/v0.2/docs/how_to/message_history/\n",
    "\n",
    "# https://python.langchain.com/v0.2/docs/tutorials/chatbot/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fa6936cd4b96a72d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-27T21:26:02.012451400Z",
     "start_time": "2024-06-27T21:26:02.012451400Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI, OpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser, MarkdownListOutputParser\n",
    "from langchain_core.messages import HumanMessage\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "11966a89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Hi Bob! How can I assist you today?', response_metadata={'token_usage': {'completion_tokens': 10, 'prompt_tokens': 11, 'total_tokens': 21}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_9b0abffe81', 'finish_reason': 'stop', 'logprobs': None}, id='run-9c15f56c-7d17-428d-9824-48c45b606c6d-0', usage_metadata={'input_tokens': 11, 'output_tokens': 10, 'total_tokens': 21})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "model = ChatOpenAI(model=\"gpt-4o-mini\")\n",
    "\n",
    "model.invoke([HumanMessage(content=\"Hi! I'm Bob\")])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8c682b4",
   "metadata": {},
   "source": [
    "O modelo não guarda a memoria, pode ser passado diretamente na chamada: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b2683324",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Your name is Bob! How can I help you today?', response_metadata={'token_usage': {'completion_tokens': 12, 'prompt_tokens': 33, 'total_tokens': 45}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_9b0abffe81', 'finish_reason': 'stop', 'logprobs': None}, id='run-3bf2e2fd-9ddf-4cf3-a268-8a3a58c98cd2-0', usage_metadata={'input_tokens': 33, 'output_tokens': 12, 'total_tokens': 45})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import AIMessage\n",
    "\n",
    "model.invoke(\n",
    "    [\n",
    "        HumanMessage(content=\"Hi! I'm Bob\"),\n",
    "        AIMessage(content=\"Hello Bob! How can I assist you today?\"),\n",
    "        HumanMessage(content=\"What's my name?\"),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0159c569",
   "metadata": {},
   "source": [
    " Existe uma melhor forma de fazer isso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ccee1d66",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.chat_history import (\n",
    "    BaseChatMessageHistory,\n",
    "    InMemoryChatMessageHistory,\n",
    ")\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
    "\n",
    "store = {}\n",
    "\n",
    "\n",
    "def get_session_history(session_id: str) -> BaseChatMessageHistory:\n",
    "    if session_id not in store:\n",
    "        store[session_id] = InMemoryChatMessageHistory()\n",
    "    return store[session_id]\n",
    "\n",
    "\n",
    "with_message_history = RunnableWithMessageHistory(model, get_session_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "65846adc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Necessario criar um config onde especificamos o session_id\n",
    "config = {\"configurable\": {\"session_id\": \"abc2\"}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b5151b00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hi Bob! How can I assist you today?'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = with_message_history.invoke(\n",
    "    [HumanMessage(content=\"Hi! I'm Bob\")],\n",
    "    config=config,\n",
    ")\n",
    "\n",
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ccffd1fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Your name is Bob! How can I help you today?'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = with_message_history.invoke(\n",
    "    [HumanMessage(content=\"What's my name?\")],\n",
    "    config=config,\n",
    ")\n",
    "\n",
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6ed28a7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'abc2': InMemoryChatMessageHistory(messages=[HumanMessage(content=\"Hi! I'm Bob\"), AIMessage(content='Hi Bob! How can I assist you today?', response_metadata={'token_usage': {'completion_tokens': 10, 'prompt_tokens': 11, 'total_tokens': 21}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_48196bc67a', 'finish_reason': 'stop', 'logprobs': None}, id='run-b0097ff5-c169-4a21-b748-01060f4ec55b-0', usage_metadata={'input_tokens': 11, 'output_tokens': 10, 'total_tokens': 21}), HumanMessage(content=\"What's my name?\"), AIMessage(content='Your name is Bob! How can I help you today?', response_metadata={'token_usage': {'completion_tokens': 12, 'prompt_tokens': 33, 'total_tokens': 45}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_48196bc67a', 'finish_reason': 'stop', 'logprobs': None}, id='run-3adfb4a1-22fa-47e8-899c-d2201204b8b4-0', usage_metadata={'input_tokens': 33, 'output_tokens': 12, 'total_tokens': 45})])}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "store"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3845ec3",
   "metadata": {},
   "source": [
    "### Prompt templates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "246349fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"You are a helpful assistant. Answer all questions to the best of your ability in {language}.\",\n",
    "        ),\n",
    "        MessagesPlaceholder(variable_name=\"messages\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "chain = prompt | model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "42203046",
   "metadata": {},
   "outputs": [],
   "source": [
    "with_message_history = RunnableWithMessageHistory(chain, get_session_history)\n",
    "config = {\"configurable\": {\"session_id\": \"abc5\"}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c913989e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'¡Hola, Bob! ¿Cómo puedo ayudarte hoy?'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = chain.invoke(\n",
    "    {\"messages\": [HumanMessage(content=\"hi! I'm bob\")], \"language\": \"Spanish\"}\n",
    ")\n",
    "\n",
    "response.content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aecd0020",
   "metadata": {},
   "source": [
    "Info: Como existe várias entradas, deve-se especificar qual será salva no histórico de menssagens "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "04ddf29b",
   "metadata": {},
   "outputs": [],
   "source": [
    "with_message_history = RunnableWithMessageHistory(\n",
    "    chain,\n",
    "    get_session_history,\n",
    "    input_messages_key=\"messages\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6264d737",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'¡Hola, Todd! ¿Cómo puedo ayudarte hoy?'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = with_message_history.invoke(\n",
    "    {\"messages\": [HumanMessage(content=\"hi! I'm todd\")], \"language\": \"Spanish\"},\n",
    "    config=config,\n",
    ")\n",
    "\n",
    "response.content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "982ba70d",
   "metadata": {},
   "source": [
    "## Managing Conversation History\n",
    "\n",
    "Um conceito importante a ser entendido ao criar chatbots é como gerenciar o histórico de conversas. Se não for gerenciada, a lista de mensagens crescerá ilimitada e potencialmente estourará a janela de contexto do LLM. Portanto, é importante adicionar uma etapa que limite o tamanho das mensagens que você está passando.\n",
    "O LangChain vem com alguns [auxiliares](https://python.langchain.com/v0.2/docs/how_to/#messages) integrados para gerenciar uma lista de mensagens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2c97a161",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SystemMessage(content=\"you're a good assistant\"),\n",
       " HumanMessage(content='whats 2 + 2'),\n",
       " AIMessage(content='4'),\n",
       " HumanMessage(content='thanks'),\n",
       " AIMessage(content='no problem!'),\n",
       " HumanMessage(content='having fun?'),\n",
       " AIMessage(content='yes!')]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import SystemMessage, trim_messages\n",
    "\n",
    "trimmer = trim_messages(\n",
    "    max_tokens=65,\n",
    "    strategy=\"last\",\n",
    "    token_counter=model,\n",
    "    include_system=True,\n",
    "    allow_partial=False,\n",
    "    start_on=\"human\",\n",
    ")\n",
    "\n",
    "messages = [\n",
    "    SystemMessage(content=\"you're a good assistant\"),\n",
    "    HumanMessage(content=\"hi! I'm bob\"),\n",
    "    AIMessage(content=\"hi!\"),\n",
    "    HumanMessage(content=\"I like vanilla ice cream\"),\n",
    "    AIMessage(content=\"nice\"),\n",
    "    HumanMessage(content=\"whats 2 + 2\"),\n",
    "    AIMessage(content=\"4\"),\n",
    "    HumanMessage(content=\"thanks\"),\n",
    "    AIMessage(content=\"no problem!\"),\n",
    "    HumanMessage(content=\"having fun?\"),\n",
    "    AIMessage(content=\"yes!\"),\n",
    "]\n",
    "\n",
    "trimmer.invoke(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a7c3c5f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"I don't know your name unless you tell me. What is your name?\""
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from operator import itemgetter\n",
    "\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "\n",
    "chain = (\n",
    "    RunnablePassthrough.assign(messages=itemgetter(\"messages\") | trimmer)\n",
    "    | prompt\n",
    "    | model\n",
    ")\n",
    "\n",
    "response = chain.invoke(\n",
    "    {\n",
    "        \"messages\": messages + [HumanMessage(content=\"what's my name?\")],\n",
    "        \"language\": \"English\",\n",
    "    }\n",
    ")\n",
    "response.content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b98341d2",
   "metadata": {},
   "source": [
    "Encapsular com o Message History"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b31b4927",
   "metadata": {},
   "outputs": [],
   "source": [
    "with_message_history = RunnableWithMessageHistory(\n",
    "    chain,\n",
    "    get_session_history,\n",
    "    input_messages_key=\"messages\",\n",
    ")\n",
    "\n",
    "config = {\"configurable\": {\"session_id\": \"abc20\"}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d389806a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"I don't know your name. What would you like me to call you?\""
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = with_message_history.invoke(\n",
    "    {\n",
    "        \"messages\": messages + [HumanMessage(content=\"whats my name?\")],\n",
    "        \"language\": \"English\",\n",
    "    },\n",
    "    config=config,\n",
    ")\n",
    "\n",
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "225c9f80",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"You haven't asked me any math problems yet. If you have one in mind, feel free to share it!\""
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = with_message_history.invoke(\n",
    "    {\n",
    "        \"messages\": [HumanMessage(content=\"what math problem did i ask?\")],\n",
    "        \"language\": \"English\",\n",
    "    },\n",
    "    config=config,\n",
    ")\n",
    "\n",
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f0d52cc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UUID personalizado para 2: 4b166dbe-d99d-5091-abdd-95b83330ed3a\n"
     ]
    }
   ],
   "source": [
    "import uuid\n",
    "\n",
    "def generate_custom_uuid(username: str) -> uuid.UUID:\n",
    "    # Usamos um namespace predefinido. O namespace DNS é comumente usado, mas você pode definir o seu próprio.\n",
    "    namespace = uuid.NAMESPACE_DNS\n",
    "    \n",
    "    # Geramos o UUIDv5 baseado no namespace e no nome de usuário.\n",
    "    custom_uuid = uuid.uuid5(namespace, username)\n",
    "    \n",
    "    return custom_uuid\n",
    "\n",
    "# Exemplo de uso\n",
    "username = \"2\"\n",
    "custom_uuid = generate_custom_uuid(username)\n",
    "print(f\"UUID personalizado para {username}: {custom_uuid}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d033e8e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      "I'm \n",
      " sorry \n",
      ", \n",
      " but \n",
      " I \n",
      " don't \n",
      " have \n",
      " access \n",
      " to \n",
      " personal \n",
      " information \n",
      " about \n",
      " users \n",
      " unless \n",
      " you \n",
      " share \n",
      " it \n",
      " with \n",
      " me \n",
      ". \n",
      " How \n",
      " can \n",
      " I \n",
      " assist \n",
      " you \n",
      " today \n",
      "? \n",
      " \n"
     ]
    }
   ],
   "source": [
    "from operator import itemgetter\n",
    "\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "\n",
    "chain = trimmer | model\n",
    "\n",
    "\n",
    "response = chain.stream(\n",
    "    [HumanMessage(content=\"what's my name?\")],       \n",
    ")\n",
    "for res in response:\n",
    "    print(res.content, '')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
