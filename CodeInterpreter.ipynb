{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ReAct vs Function Calling vs Router\n",
    "\n",
    "ReAct, Function Calling e Router são abordagens diferentes usadas para melhorar as interações com modelos de linguagem, especialmente no contexto de sistemas que exigem maior precisão, estrutura ou capacidade de execução de tarefas específicas. Vamos detalhar cada uma:\n",
    "\n",
    "### 1. **ReAct (Reasoning and Acting)**\n",
    "ReAct é uma técnica que combina raciocínio (reasoning) com ações (acting). Aqui, o modelo não apenas gera uma resposta, mas também pode tomar decisões e executar ações com base no raciocínio que faz ao longo do processo de geração de texto. Ele é útil para casos onde é necessário que o modelo tome passos intermediários para chegar a uma resposta final.  \n",
    "Artigo: https://arxiv.org/pdf/2210.03629\n",
    "\n",
    "**Exemplo de uso:** Se o modelo precisar resolver um problema de lógica ou realizar cálculos complexos, ele pode \"pensar em voz alta\" (gerar passos de raciocínio intermediários) e, em seguida, tomar ações apropriadas, como selecionar dados ou fazer cálculos, antes de chegar à resposta final.\n",
    "\n",
    "### 2. **Function Calling**\n",
    "O **Function Calling** permite que o modelo de linguagem chame funções específicas durante sua execução. Essa abordagem é útil para integração direta com APIs ou funções do sistema. Quando o modelo identifica que uma determinada tarefa deve ser executada por uma função predefinida (como buscar dados em uma API, realizar cálculos complexos ou manipular dados), ele invoca essa função e utiliza o resultado na sua resposta.  \n",
    "documentação:\n",
    "* https://python.langchain.com/v0.2/docs/how_to/function_calling/\n",
    "* https://python.langchain.com/v0.2/docs/how_to/tool_calling/\n",
    "\n",
    "**Exemplo de uso:** Se o usuário pedir a previsão do tempo, o modelo pode chamar uma função que consulta uma API de clima, obter os dados necessários e, em seguida, apresentar a previsão ao usuário.\n",
    "\n",
    "### 3. **Router**\n",
    "O **Router** refere-se a um sistema ou mecanismo que decide para onde deve ser encaminhada uma determinada solicitação ou tarefa, com base em regras, modelos ou critérios predefinidos. Em vez de o modelo processar diretamente todas as solicitações, o Router pode direcionar cada solicitação para o módulo ou serviço mais apropriado, que pode ser outro modelo, um conjunto de funções específicas ou até um serviço externo.\n",
    "\n",
    "**Exemplo de uso:** Se um sistema tiver diferentes módulos especializados (por exemplo, um para linguagem natural, outro para consultas a bancos de dados, e outro para cálculos matemáticos), o Router decide qual módulo deve lidar com a solicitação do usuário. Por exemplo, uma consulta matemática seria enviada para o módulo de cálculos, enquanto uma pergunta sobre dados de clientes poderia ser enviada para um módulo de consulta a bancos de dados.\n",
    "\n",
    "### Comparação e Usos Comuns\n",
    "- **ReAct** é ideal para tarefas que exigem raciocínio intermediário, como resolução de problemas ou quebra-cabeças, onde o processo de \"pensar em voz alta\" é importante.\n",
    "- **Function Calling** é útil quando o modelo precisa interagir diretamente com APIs ou executar funções específicas que requerem dados dinâmicos ou processamento externo.\n",
    "- **Router** é usado em sistemas complexos com múltiplos módulos, permitindo que as solicitações sejam encaminhadas para os recursos ou serviços mais adequados.\n",
    "\n",
    "Cada abordagem tem suas vantagens específicas dependendo do contexto e das necessidades do sistema em que estão implementadas.\n",
    "\n",
    "https://python.langchain.com/v0.2/docs/how_to/routing/\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 Agent router\n",
    "<img src='assets/imgs/agent.bmp' width='600'></img>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from typing import Any\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "from langchain import hub\n",
    "from langchain_core.tools import Tool\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.agents import (\n",
    "    create_react_agent,\n",
    "    AgentExecutor,\n",
    "    AgentType\n",
    ")\n",
    "from langchain.prompts import PromptTemplate, ChatPromptTemplate\n",
    "from langchain_experimental.tools import PythonREPLTool\n",
    "from langchain_experimental.agents.agent_toolkits import create_csv_agent\n",
    "\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definindo os agentes ou LLMs com suas respectivas tarefas \n",
    " * Temos dois agentes:\n",
    "   - Executa código python\n",
    "   - Interação com dados em csv\n",
    " * LLM genérico"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "instructions = \"\"\"You are an agent designed to write and execute python code to answer questions.\n",
    "You have access to a python REPL, which you can use to execute python code.\n",
    "You have qrcode package installed\n",
    "If you get an error, debug your code and not try again.\n",
    "Only use the output of your code to answer the question. \n",
    "You might know the answer without running any code, but you should still run the code to get the answer.\n",
    "If it does not seem like you can write code to answer the question, just return \"I don't know\" as the answer.\n",
    "    \"\"\"\n",
    "    \n",
    "template_react_agent =\"\"\"\n",
    "    {instructions}\n",
    "\n",
    "    TOOLS:\n",
    "    ------\n",
    "\n",
    "    You have access to the following tools:\n",
    "\n",
    "    {tools}\n",
    "\n",
    "    To use a tool, please use the following format:\n",
    "\n",
    "    ```\n",
    "    Thought: Do I need to use a tool? Yes\n",
    "    Action: the action to take, should be one of [{tool_names}]\n",
    "    Action Input: the input to the action\n",
    "    Observation: the result of the action\n",
    "    ```\n",
    "\n",
    "    When you have a response to say to the Human, or if you do not need to use a tool, you MUST use the format:\n",
    "\n",
    "    ```\n",
    "    Thought: Do I need to use a tool? No\n",
    "    Final Answer: [your response here]\n",
    "    ```\n",
    "\n",
    "    Begin!\n",
    "\n",
    "    Previous conversation history:\n",
    "    {chat_history}\n",
    "\n",
    "    New input: {input}\n",
    "    {agent_scratchpad}\n",
    "\"\"\"\n",
    "# base_prompt = hub.pull(\"langchain-ai/react-agent-template\")    \n",
    "base_prompt = PromptTemplate.from_template(template_react_agent)\n",
    "\n",
    "prompt = base_prompt.partial(instructions=instructions, chat_history='')\n",
    "\n",
    "tools = [PythonREPLTool()]\n",
    "python_agent = create_react_agent(\n",
    "    prompt=prompt,\n",
    "    llm=ChatOpenAI(temperature=0, model=\"gpt-4o-mini\"),\n",
    "    tools=tools,\n",
    ")\n",
    "\n",
    "python_agent_executor = AgentExecutor(agent=python_agent, tools=tools, verbose=False)\n",
    "\n",
    "csv_agent_executor: AgentExecutor = create_csv_agent(\n",
    "    llm=ChatOpenAI(temperature=0, model='gpt-4o-mini'),\n",
    "    path='data/iris.csv',\n",
    "    verbose=False,\n",
    "    # agent_type=AgentType.ZERO_SHOT_REACT_DESCRIPTION,\n",
    "    allow_dangerous_code=True,\n",
    "    \n",
    ")\n",
    "\n",
    "generic_chain = ChatOpenAI(temperature=.5, model='gpt-4o-mini')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Necessário envolver os agentes/chain... com a classe Tools. Criamos um agente que séra responsavél por realizar o direcionamento para a ferramenta adequada "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ################################ Router Grand Agent ########################################################\n",
    "\n",
    "\n",
    "def python_agent_executor_wrapper(original_prompt: str) -> dict[str, Any]:\n",
    "    return python_agent_executor.invoke({\"input\": original_prompt})\n",
    "\n",
    "tools = [\n",
    "    Tool(\n",
    "        name=\"Python Agent\",\n",
    "        func=python_agent_executor_wrapper,\n",
    "        description=\"\"\"useful when you need to transform natural language to python and execute the python code,\n",
    "                        returning the results of the code execution\n",
    "                        DOES NOT ACCEPT CODE AS INPUT\"\"\",\n",
    "    ),\n",
    "    Tool(\n",
    "        name=\"CSV Agent\",\n",
    "        func=csv_agent_executor.invoke,\n",
    "        description=\"\"\"useful when you need to answer question over iris.csv file,\n",
    "                        takes an input the entire question and returns the answer after running pandas calculations\"\"\",\n",
    "    ),\n",
    "     Tool(\n",
    "        name=\"Generic chain\",\n",
    "        func=generic_chain.invoke,\n",
    "        description=\"\"\"use it when you want an answer that doesn't fit into the other tools. It is a generic tool\"\"\",\n",
    "    ),\n",
    "]\n",
    "\n",
    "prompt = base_prompt.partial(instructions=\"\", chat_history='')\n",
    "\n",
    "grand_agent = create_react_agent(\n",
    "    prompt=prompt,\n",
    "    llm=ChatOpenAI(temperature=0, model='gpt-4o-mini'),\n",
    "    tools=tools\n",
    ")\n",
    "\n",
    "grand_agent_executor = AgentExecutor(agent=grand_agent, tools=tools)  # faz o papel do router\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input': 'Conte uma piada',\n",
       " 'output': 'Por que o livro de matemática se suicidou? Porque ele tinha muitos problemas!\\n```'}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grand_agent_executor.invoke(\n",
    "        {\n",
    "            \"input\": \"Conte uma piada\",\n",
    "        }\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mThought: Para calcular a média de comprimento das flores, preciso calcular a média da coluna `petal.length` do dataframe `df`. Vou fazer isso agora.\n",
      "Action: python_repl_ast\n",
      "Action Input: df['petal.length'].mean()\u001b[0m\u001b[36;1m\u001b[1;3m3.7580000000000005\u001b[0m\u001b[32;1m\u001b[1;3mI now know the final answer\n",
      "Final Answer: A média de comprimento das flores é aproximadamente 3.76.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'Qual a média de comprimento das flores?',\n",
       " 'output': 'A média de comprimento das flores é aproximadamente 3.76.\\n```'}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grand_agent_executor.invoke(\n",
    "    {\n",
    "        \"input\": \"Qual a média de comprimento das flores?\",\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grand_agent_executor.invoke(\n",
    "    {\n",
    "        \"input\": \"Generate and save in current working directory 15 qrcodes that point to `https://github.com/silva-fabiofreitas/`\",\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 Function calling\n",
    "Definindo as ferramentas ou funções.  \n",
    "**Observação:** ao usar bind_tools o nome da função deve ter \"_\"  \n",
    "\n",
    "<img src='assets/imgs/toolCalling.bmp' width=800></img>\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def python_agent_executor_wrapper(original_prompt: str) -> dict[str, Any]:\n",
    "    return python_agent_executor.invoke({\"input\": original_prompt})\n",
    "\n",
    "tools = [\n",
    "    Tool(\n",
    "        name=\"Python_Agent\",\n",
    "        func=python_agent_executor_wrapper,\n",
    "        description=\"\"\"useful when you need to transform natural language to python and execute the python code,\n",
    "                        returning the results of the code execution\n",
    "                        DOES NOT ACCEPT CODE AS INPUT\"\"\",\n",
    "    ),\n",
    "    Tool(\n",
    "        name=\"CSV_Agent\",\n",
    "        func=csv_agent_executor.invoke,\n",
    "        description=\"\"\"useful when you need to answer question over iris.csv file,\n",
    "                        takes an input the entire question and returns the answer after running pandas calculations\"\"\",\n",
    "    ),\n",
    "     Tool(\n",
    "        name=\"Generic_chain\",\n",
    "        func=generic_chain.invoke,\n",
    "        description=\"\"\"use it when you want an answer that doesn't fit into the other tools. It is a generic tool\"\"\",\n",
    "    ),\n",
    "]\n",
    "\n",
    "# Outra forma de declarar as ferramentas \n",
    "\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "\n",
    "class Python_Agent(BaseModel):\n",
    "    \"\"\"useful when you need to transform natural language to python and execute the python code,\n",
    "       returning the results of the code execution\n",
    "       DOES NOT ACCEPT CODE AS INPUT.\"\"\"\n",
    "\n",
    "    input: str = Field(..., description=\"Text\")\n",
    "\n",
    "class CSV_Agent(BaseModel):\n",
    "    \"\"\"useful when you need to answer question over iris.csv file,\n",
    "        takes an input the entire question and returns the answer after running pandas calculations\"\"\"\n",
    "\n",
    "    input: str = Field(..., description=\"Text\")\n",
    "\n",
    "class Generic_chain(BaseModel):\n",
    "    \"\"\"use it when you want an answer that doesn't fit into the other tools. It is a generic tool\"\"\"\n",
    "\n",
    "    input: str = Field(..., description=\"Text\")\n",
    "    \n",
    "tools_pydantic = [Python_Agent, CSV_Agent, Generic_chain]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "\n",
    "class Python_Agent(BaseModel):\n",
    "    \"\"\"useful when you need to transform natural language to python and execute the python code,\n",
    "       returning the results of the code execution\n",
    "       DOES NOT ACCEPT CODE AS INPUT.\"\"\"\n",
    "\n",
    "    input: str = Field(..., description=\"Text\")\n",
    "\n",
    "class CSV_Agent(BaseModel):\n",
    "    \"\"\"useful when you need to answer question over iris.csv file,\n",
    "        takes an input the entire question and returns the answer after running pandas calculations\"\"\"\n",
    "\n",
    "    input: str = Field(..., description=\"Text\")\n",
    "\n",
    "class Generic_chain(BaseModel):\n",
    "    \"\"\"use it when you want an answer that doesn't fit into the other tools. It is a generic tool\"\"\"\n",
    "\n",
    "    input: str = Field(..., description=\"Text\")\n",
    "    \n",
    "tools_pydantic = [Python_Agent, CSV_Agent, Generic_chain]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'name': 'CSV_Agent', 'args': {'args': ['Qual a média de comprimento das flores?'], 'config': {'tags': []}}, 'id': 'call_FhjJzzlcW1yRAhxzg6AqBzMS', 'type': 'tool_call'}]\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\")\n",
    "\n",
    "llm_with_tools = llm.bind_tools(tools)\n",
    "\n",
    "query = \"Qual a média de comprimento das flores?\"\n",
    "# query = \"Conte uma piada?\"\n",
    "\n",
    "messages = [HumanMessage(query)]\n",
    "\n",
    "# LLM escolhe a função a ser usada\n",
    "ai_msg = llm_with_tools.invoke(messages)\n",
    "\n",
    "print(ai_msg.tool_calls)\n",
    "\n",
    "messages.append(ai_msg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Parse output\n",
    "\n",
    "<img src=\"assets/imgs/toolCallingParseOutput.bmp\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[HumanMessage(content='Conte uma piada?'),\n",
       " AIMessage(content='Por que o livro de matemática se suicidou?\\n\\nPorque tinha muitos problemas!', response_metadata={'token_usage': {'completion_tokens': 17, 'prompt_tokens': 284, 'total_tokens': 301}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_f33667828e', 'finish_reason': 'stop', 'logprobs': None}, id='run-46057c20-7d2f-4f29-9173-df7cffc2ca58-0', usage_metadata={'input_tokens': 284, 'output_tokens': 17, 'total_tokens': 301})]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for tool_call in ai_msg.tool_calls:\n",
    "    selected_tool = {\"Python_Agent\": python_agent_executor_wrapper, \"CSV_Agent\": csv_agent_executor.invoke, 'Generic_chain':generic_chain.invoke}[tool_call[\"name\"]]\n",
    "    tool_msg = selected_tool({'input':tool_call})\n",
    "    messages.append(tool_msg)\n",
    "\n",
    "messages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 Router"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'python_code'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\")\n",
    "\n",
    "chain = (\n",
    "    PromptTemplate.from_template(\n",
    "        \"\"\"Given the user question below, classify it as either being about `python_code`, `query`, or `Other`.\n",
    "        \n",
    "        python_code: useful when you need to transform natural language to python and execute the python code.\n",
    "        \n",
    "        query: useful when you need to answer question over iris.csv file,takes an input the entire question and returns the answer after running pandas calculations.\n",
    "        \n",
    "        Other: use it when you want an answer that doesn't fit into the other tools. It is a generic tool.\n",
    "\n",
    "Do not respond with more than one word.\n",
    "\n",
    "<question>\n",
    "{input}\n",
    "</question>\n",
    "\n",
    "Classification:\"\"\"\n",
    "    )\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "chain.invoke({\"input\": \"Code python\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "generic_chain = PromptTemplate.from_template(\n",
    "    \"\"\"Respond to the following question:\n",
    "\n",
    "Question: {input}\n",
    "Answer:\"\"\"\n",
    ") | ChatOpenAI(temperature=.5, model='gpt-4o-mini')\n",
    "\n",
    "\n",
    "def route(info):\n",
    "    if \"python_code\" in info[\"topic\"].lower():\n",
    "        return python_agent_executor_wrapper\n",
    "    elif \"query\" in info[\"topic\"].lower():\n",
    "        return csv_agent_executor\n",
    "    else:\n",
    "        return generic_chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables import RunnableLambda, RunnablePassthrough\n",
    "\n",
    "full_chain = {'topic': chain, 'input':lambda x: x['input']} | RunnableLambda(route)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'topic': 'query',\n",
       " 'input': 'Qual a média de comprimento das flores?',\n",
       " 'output': 'A média de comprimento das flores é aproximadamente 3.76.'}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"Qual a média de comprimento das flores?\"\n",
    "\n",
    "full_chain.invoke({'input':query})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Claro! Aqui vai uma:\\n\\nPor que o livro de matemática se suicidou?\\n\\nPorque tinha muitos problemas! 😄', response_metadata={'token_usage': {'completion_tokens': 24, 'prompt_tokens': 22, 'total_tokens': 46}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_f33667828e', 'finish_reason': 'stop', 'logprobs': None}, id='run-468b4694-d9a6-4a1e-b430-9552e54d38fc-0', usage_metadata={'input_tokens': 22, 'output_tokens': 24, 'total_tokens': 46})"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"Conte uma piada?\"\n",
    "\n",
    "full_chain.invoke({'input':query})\n",
    "# generic_chain.invoke(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2+"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
