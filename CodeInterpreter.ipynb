{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ReAct vs Function Calling vs Router\n",
    "\n",
    "ReAct, Function Calling e Router s√£o abordagens diferentes usadas para melhorar as intera√ß√µes com modelos de linguagem, especialmente no contexto de sistemas que exigem maior precis√£o, estrutura ou capacidade de execu√ß√£o de tarefas espec√≠ficas. Vamos detalhar cada uma:\n",
    "\n",
    "### 1. **ReAct (Reasoning and Acting)**\n",
    "ReAct √© uma t√©cnica que combina racioc√≠nio (reasoning) com a√ß√µes (acting). Aqui, o modelo n√£o apenas gera uma resposta, mas tamb√©m pode tomar decis√µes e executar a√ß√µes com base no racioc√≠nio que faz ao longo do processo de gera√ß√£o de texto. Ele √© √∫til para casos onde √© necess√°rio que o modelo tome passos intermedi√°rios para chegar a uma resposta final.  \n",
    "Artigo: https://arxiv.org/pdf/2210.03629\n",
    "\n",
    "**Exemplo de uso:** Se o modelo precisar resolver um problema de l√≥gica ou realizar c√°lculos complexos, ele pode \"pensar em voz alta\" (gerar passos de racioc√≠nio intermedi√°rios) e, em seguida, tomar a√ß√µes apropriadas, como selecionar dados ou fazer c√°lculos, antes de chegar √† resposta final.\n",
    "\n",
    "### 2. **Function Calling**\n",
    "O **Function Calling** permite que o modelo de linguagem chame fun√ß√µes espec√≠ficas durante sua execu√ß√£o. Essa abordagem √© √∫til para integra√ß√£o direta com APIs ou fun√ß√µes do sistema. Quando o modelo identifica que uma determinada tarefa deve ser executada por uma fun√ß√£o predefinida (como buscar dados em uma API, realizar c√°lculos complexos ou manipular dados), ele invoca essa fun√ß√£o e utiliza o resultado na sua resposta.  \n",
    "documenta√ß√£o:\n",
    "* https://python.langchain.com/v0.2/docs/how_to/function_calling/\n",
    "* https://python.langchain.com/v0.2/docs/how_to/tool_calling/\n",
    "\n",
    "**Exemplo de uso:** Se o usu√°rio pedir a previs√£o do tempo, o modelo pode chamar uma fun√ß√£o que consulta uma API de clima, obter os dados necess√°rios e, em seguida, apresentar a previs√£o ao usu√°rio.\n",
    "\n",
    "### 3. **Router**\n",
    "O **Router** refere-se a um sistema ou mecanismo que decide para onde deve ser encaminhada uma determinada solicita√ß√£o ou tarefa, com base em regras, modelos ou crit√©rios predefinidos. Em vez de o modelo processar diretamente todas as solicita√ß√µes, o Router pode direcionar cada solicita√ß√£o para o m√≥dulo ou servi√ßo mais apropriado, que pode ser outro modelo, um conjunto de fun√ß√µes espec√≠ficas ou at√© um servi√ßo externo.\n",
    "\n",
    "**Exemplo de uso:** Se um sistema tiver diferentes m√≥dulos especializados (por exemplo, um para linguagem natural, outro para consultas a bancos de dados, e outro para c√°lculos matem√°ticos), o Router decide qual m√≥dulo deve lidar com a solicita√ß√£o do usu√°rio. Por exemplo, uma consulta matem√°tica seria enviada para o m√≥dulo de c√°lculos, enquanto uma pergunta sobre dados de clientes poderia ser enviada para um m√≥dulo de consulta a bancos de dados.\n",
    "\n",
    "### Compara√ß√£o e Usos Comuns\n",
    "- **ReAct** √© ideal para tarefas que exigem racioc√≠nio intermedi√°rio, como resolu√ß√£o de problemas ou quebra-cabe√ßas, onde o processo de \"pensar em voz alta\" √© importante.\n",
    "- **Function Calling** √© √∫til quando o modelo precisa interagir diretamente com APIs ou executar fun√ß√µes espec√≠ficas que requerem dados din√¢micos ou processamento externo.\n",
    "- **Router** √© usado em sistemas complexos com m√∫ltiplos m√≥dulos, permitindo que as solicita√ß√µes sejam encaminhadas para os recursos ou servi√ßos mais adequados.\n",
    "\n",
    "Cada abordagem tem suas vantagens espec√≠ficas dependendo do contexto e das necessidades do sistema em que est√£o implementadas.\n",
    "\n",
    "https://python.langchain.com/v0.2/docs/how_to/routing/\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 Agent router\n",
    "<img src='assets/imgs/agent.bmp' width='600'></img>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from typing import Any\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "from langchain import hub\n",
    "from langchain_core.tools import Tool\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.agents import (\n",
    "    create_react_agent,\n",
    "    AgentExecutor,\n",
    "    AgentType\n",
    ")\n",
    "from langchain.prompts import PromptTemplate, ChatPromptTemplate\n",
    "from langchain_experimental.tools import PythonREPLTool\n",
    "from langchain_experimental.agents.agent_toolkits import create_csv_agent\n",
    "\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definindo os agentes ou LLMs com suas respectivas tarefas \n",
    " * Temos dois agentes:\n",
    "   - Executa c√≥digo python\n",
    "   - Intera√ß√£o com dados em csv\n",
    " * LLM gen√©rico"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "instructions = \"\"\"You are an agent designed to write and execute python code to answer questions.\n",
    "You have access to a python REPL, which you can use to execute python code.\n",
    "You have qrcode package installed\n",
    "If you get an error, debug your code and not try again.\n",
    "Only use the output of your code to answer the question. \n",
    "You might know the answer without running any code, but you should still run the code to get the answer.\n",
    "If it does not seem like you can write code to answer the question, just return \"I don't know\" as the answer.\n",
    "    \"\"\"\n",
    "    \n",
    "template_react_agent =\"\"\"\n",
    "    {instructions}\n",
    "\n",
    "    TOOLS:\n",
    "    ------\n",
    "\n",
    "    You have access to the following tools:\n",
    "\n",
    "    {tools}\n",
    "\n",
    "    To use a tool, please use the following format:\n",
    "\n",
    "    ```\n",
    "    Thought: Do I need to use a tool? Yes\n",
    "    Action: the action to take, should be one of [{tool_names}]\n",
    "    Action Input: the input to the action\n",
    "    Observation: the result of the action\n",
    "    ```\n",
    "\n",
    "    When you have a response to say to the Human, or if you do not need to use a tool, you MUST use the format:\n",
    "\n",
    "    ```\n",
    "    Thought: Do I need to use a tool? No\n",
    "    Final Answer: [your response here]\n",
    "    ```\n",
    "\n",
    "    Begin!\n",
    "\n",
    "    Previous conversation history:\n",
    "    {chat_history}\n",
    "\n",
    "    New input: {input}\n",
    "    {agent_scratchpad}\n",
    "\"\"\"\n",
    "# base_prompt = hub.pull(\"langchain-ai/react-agent-template\")    \n",
    "base_prompt = PromptTemplate.from_template(template_react_agent)\n",
    "\n",
    "prompt = base_prompt.partial(instructions=instructions, chat_history='')\n",
    "\n",
    "tools = [PythonREPLTool()]\n",
    "python_agent = create_react_agent(\n",
    "    prompt=prompt,\n",
    "    llm=ChatOpenAI(temperature=0, model=\"gpt-4o-mini\"),\n",
    "    tools=tools,\n",
    ")\n",
    "\n",
    "python_agent_executor = AgentExecutor(agent=python_agent, tools=tools, verbose=False)\n",
    "\n",
    "csv_agent_executor: AgentExecutor = create_csv_agent(\n",
    "    llm=ChatOpenAI(temperature=0, model='gpt-4o-mini'),\n",
    "    path='data/iris.csv',\n",
    "    verbose=False,\n",
    "    # agent_type=AgentType.ZERO_SHOT_REACT_DESCRIPTION,\n",
    "    allow_dangerous_code=True,\n",
    "    \n",
    ")\n",
    "\n",
    "generic_chain = ChatOpenAI(temperature=.5, model='gpt-4o-mini')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Necess√°rio envolver os agentes/chain... com a classe Tools. Criamos um agente que s√©ra responsav√©l por realizar o direcionamento para a ferramenta adequada "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ################################ Router Grand Agent ########################################################\n",
    "\n",
    "\n",
    "def python_agent_executor_wrapper(original_prompt: str) -> dict[str, Any]:\n",
    "    return python_agent_executor.invoke({\"input\": original_prompt})\n",
    "\n",
    "tools = [\n",
    "    Tool(\n",
    "        name=\"Python Agent\",\n",
    "        func=python_agent_executor_wrapper,\n",
    "        description=\"\"\"useful when you need to transform natural language to python and execute the python code,\n",
    "                        returning the results of the code execution\n",
    "                        DOES NOT ACCEPT CODE AS INPUT\"\"\",\n",
    "    ),\n",
    "    Tool(\n",
    "        name=\"CSV Agent\",\n",
    "        func=csv_agent_executor.invoke,\n",
    "        description=\"\"\"useful when you need to answer question over iris.csv file,\n",
    "                        takes an input the entire question and returns the answer after running pandas calculations\"\"\",\n",
    "    ),\n",
    "     Tool(\n",
    "        name=\"Generic chain\",\n",
    "        func=generic_chain.invoke,\n",
    "        description=\"\"\"use it when you want an answer that doesn't fit into the other tools. It is a generic tool\"\"\",\n",
    "    ),\n",
    "]\n",
    "\n",
    "prompt = base_prompt.partial(instructions=\"\", chat_history='')\n",
    "\n",
    "grand_agent = create_react_agent(\n",
    "    prompt=prompt,\n",
    "    llm=ChatOpenAI(temperature=0, model='gpt-4o-mini'),\n",
    "    tools=tools\n",
    ")\n",
    "\n",
    "grand_agent_executor = AgentExecutor(agent=grand_agent, tools=tools)  # faz o papel do router\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input': 'Conte uma piada',\n",
       " 'output': 'Por que o livro de matem√°tica se suicidou? Porque ele tinha muitos problemas!\\n```'}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grand_agent_executor.invoke(\n",
    "        {\n",
    "            \"input\": \"Conte uma piada\",\n",
    "        }\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mThought: Para calcular a m√©dia de comprimento das flores, preciso calcular a m√©dia da coluna `petal.length` do dataframe `df`. Vou fazer isso agora.\n",
      "Action: python_repl_ast\n",
      "Action Input: df['petal.length'].mean()\u001b[0m\u001b[36;1m\u001b[1;3m3.7580000000000005\u001b[0m\u001b[32;1m\u001b[1;3mI now know the final answer\n",
      "Final Answer: A m√©dia de comprimento das flores √© aproximadamente 3.76.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'Qual a m√©dia de comprimento das flores?',\n",
       " 'output': 'A m√©dia de comprimento das flores √© aproximadamente 3.76.\\n```'}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grand_agent_executor.invoke(\n",
    "    {\n",
    "        \"input\": \"Qual a m√©dia de comprimento das flores?\",\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grand_agent_executor.invoke(\n",
    "    {\n",
    "        \"input\": \"Generate and save in current working directory 15 qrcodes that point to `https://github.com/silva-fabiofreitas/`\",\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 Function calling\n",
    "Definindo as ferramentas ou fun√ß√µes.  \n",
    "**Observa√ß√£o:** ao usar bind_tools o nome da fun√ß√£o deve ter \"_\"  \n",
    "\n",
    "<img src='assets/imgs/toolCalling.bmp' width=800></img>\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def python_agent_executor_wrapper(original_prompt: str) -> dict[str, Any]:\n",
    "    return python_agent_executor.invoke({\"input\": original_prompt})\n",
    "\n",
    "tools = [\n",
    "    Tool(\n",
    "        name=\"Python_Agent\",\n",
    "        func=python_agent_executor_wrapper,\n",
    "        description=\"\"\"useful when you need to transform natural language to python and execute the python code,\n",
    "                        returning the results of the code execution\n",
    "                        DOES NOT ACCEPT CODE AS INPUT\"\"\",\n",
    "    ),\n",
    "    Tool(\n",
    "        name=\"CSV_Agent\",\n",
    "        func=csv_agent_executor.invoke,\n",
    "        description=\"\"\"useful when you need to answer question over iris.csv file,\n",
    "                        takes an input the entire question and returns the answer after running pandas calculations\"\"\",\n",
    "    ),\n",
    "     Tool(\n",
    "        name=\"Generic_chain\",\n",
    "        func=generic_chain.invoke,\n",
    "        description=\"\"\"use it when you want an answer that doesn't fit into the other tools. It is a generic tool\"\"\",\n",
    "    ),\n",
    "]\n",
    "\n",
    "# Outra forma de declarar as ferramentas \n",
    "\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "\n",
    "class Python_Agent(BaseModel):\n",
    "    \"\"\"useful when you need to transform natural language to python and execute the python code,\n",
    "       returning the results of the code execution\n",
    "       DOES NOT ACCEPT CODE AS INPUT.\"\"\"\n",
    "\n",
    "    input: str = Field(..., description=\"Text\")\n",
    "\n",
    "class CSV_Agent(BaseModel):\n",
    "    \"\"\"useful when you need to answer question over iris.csv file,\n",
    "        takes an input the entire question and returns the answer after running pandas calculations\"\"\"\n",
    "\n",
    "    input: str = Field(..., description=\"Text\")\n",
    "\n",
    "class Generic_chain(BaseModel):\n",
    "    \"\"\"use it when you want an answer that doesn't fit into the other tools. It is a generic tool\"\"\"\n",
    "\n",
    "    input: str = Field(..., description=\"Text\")\n",
    "    \n",
    "tools_pydantic = [Python_Agent, CSV_Agent, Generic_chain]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "\n",
    "class Python_Agent(BaseModel):\n",
    "    \"\"\"useful when you need to transform natural language to python and execute the python code,\n",
    "       returning the results of the code execution\n",
    "       DOES NOT ACCEPT CODE AS INPUT.\"\"\"\n",
    "\n",
    "    input: str = Field(..., description=\"Text\")\n",
    "\n",
    "class CSV_Agent(BaseModel):\n",
    "    \"\"\"useful when you need to answer question over iris.csv file,\n",
    "        takes an input the entire question and returns the answer after running pandas calculations\"\"\"\n",
    "\n",
    "    input: str = Field(..., description=\"Text\")\n",
    "\n",
    "class Generic_chain(BaseModel):\n",
    "    \"\"\"use it when you want an answer that doesn't fit into the other tools. It is a generic tool\"\"\"\n",
    "\n",
    "    input: str = Field(..., description=\"Text\")\n",
    "    \n",
    "tools_pydantic = [Python_Agent, CSV_Agent, Generic_chain]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'name': 'CSV_Agent', 'args': {'args': ['Qual a m√©dia de comprimento das flores?'], 'config': {'tags': []}}, 'id': 'call_FhjJzzlcW1yRAhxzg6AqBzMS', 'type': 'tool_call'}]\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\")\n",
    "\n",
    "llm_with_tools = llm.bind_tools(tools)\n",
    "\n",
    "query = \"Qual a m√©dia de comprimento das flores?\"\n",
    "# query = \"Conte uma piada?\"\n",
    "\n",
    "messages = [HumanMessage(query)]\n",
    "\n",
    "# LLM escolhe a fun√ß√£o a ser usada\n",
    "ai_msg = llm_with_tools.invoke(messages)\n",
    "\n",
    "print(ai_msg.tool_calls)\n",
    "\n",
    "messages.append(ai_msg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Parse output\n",
    "\n",
    "<img src=\"assets/imgs/toolCallingParseOutput.bmp\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[HumanMessage(content='Conte uma piada?'),\n",
       " AIMessage(content='Por que o livro de matem√°tica se suicidou?\\n\\nPorque tinha muitos problemas!', response_metadata={'token_usage': {'completion_tokens': 17, 'prompt_tokens': 284, 'total_tokens': 301}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_f33667828e', 'finish_reason': 'stop', 'logprobs': None}, id='run-46057c20-7d2f-4f29-9173-df7cffc2ca58-0', usage_metadata={'input_tokens': 284, 'output_tokens': 17, 'total_tokens': 301})]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for tool_call in ai_msg.tool_calls:\n",
    "    selected_tool = {\"Python_Agent\": python_agent_executor_wrapper, \"CSV_Agent\": csv_agent_executor.invoke, 'Generic_chain':generic_chain.invoke}[tool_call[\"name\"]]\n",
    "    tool_msg = selected_tool({'input':tool_call})\n",
    "    messages.append(tool_msg)\n",
    "\n",
    "messages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 Router"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'python_code'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\")\n",
    "\n",
    "chain = (\n",
    "    PromptTemplate.from_template(\n",
    "        \"\"\"Given the user question below, classify it as either being about `python_code`, `query`, or `Other`.\n",
    "        \n",
    "        python_code: useful when you need to transform natural language to python and execute the python code.\n",
    "        \n",
    "        query: useful when you need to answer question over iris.csv file,takes an input the entire question and returns the answer after running pandas calculations.\n",
    "        \n",
    "        Other: use it when you want an answer that doesn't fit into the other tools. It is a generic tool.\n",
    "\n",
    "Do not respond with more than one word.\n",
    "\n",
    "<question>\n",
    "{input}\n",
    "</question>\n",
    "\n",
    "Classification:\"\"\"\n",
    "    )\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "chain.invoke({\"input\": \"Code python\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "generic_chain = PromptTemplate.from_template(\n",
    "    \"\"\"Respond to the following question:\n",
    "\n",
    "Question: {input}\n",
    "Answer:\"\"\"\n",
    ") | ChatOpenAI(temperature=.5, model='gpt-4o-mini')\n",
    "\n",
    "\n",
    "def route(info):\n",
    "    if \"python_code\" in info[\"topic\"].lower():\n",
    "        return python_agent_executor_wrapper\n",
    "    elif \"query\" in info[\"topic\"].lower():\n",
    "        return csv_agent_executor\n",
    "    else:\n",
    "        return generic_chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables import RunnableLambda, RunnablePassthrough\n",
    "\n",
    "full_chain = {'topic': chain, 'input':lambda x: x['input']} | RunnableLambda(route)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'topic': 'query',\n",
       " 'input': 'Qual a m√©dia de comprimento das flores?',\n",
       " 'output': 'A m√©dia de comprimento das flores √© aproximadamente 3.76.'}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"Qual a m√©dia de comprimento das flores?\"\n",
    "\n",
    "full_chain.invoke({'input':query})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Claro! Aqui vai uma:\\n\\nPor que o livro de matem√°tica se suicidou?\\n\\nPorque tinha muitos problemas! üòÑ', response_metadata={'token_usage': {'completion_tokens': 24, 'prompt_tokens': 22, 'total_tokens': 46}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_f33667828e', 'finish_reason': 'stop', 'logprobs': None}, id='run-468b4694-d9a6-4a1e-b430-9552e54d38fc-0', usage_metadata={'input_tokens': 22, 'output_tokens': 24, 'total_tokens': 46})"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"Conte uma piada?\"\n",
    "\n",
    "full_chain.invoke({'input':query})\n",
    "# generic_chain.invoke(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2+"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
