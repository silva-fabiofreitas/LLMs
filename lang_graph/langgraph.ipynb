{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reflection Agent\n",
    "**Chain**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "reflection_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"You are a viral twitter influencer grading a tweet. Generate critique and recommendations for the user's tweet.\"\n",
    "            \"Always provide detailed recommendations, including requests for length, virality, style, etc.\",\n",
    "        ),\n",
    "        MessagesPlaceholder(variable_name=\"messages\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "generation_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"You are a twitter techie influencer assistant tasked with writing excellent twitter posts.\"\n",
    "            \" Generate the best twitter post possible for the user's request.\"\n",
    "            \" If the user provides critique, respond with a revised version of your previous attempts.\",\n",
    "        ),\n",
    "        MessagesPlaceholder(variable_name=\"messages\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "llm = ChatOpenAI()\n",
    "generate_chain = generation_prompt | llm\n",
    "reflect_chain = reflection_prompt | llm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Main**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "%%{init: {'flowchart': {'curve': 'linear'}}}%%\n",
      "graph TD;\n",
      "\t__start__([<p>__start__</p>]):::first\n",
      "\tgenerate(generate)\n",
      "\treflect(reflect)\n",
      "\t__end__([<p>__end__</p>]):::last\n",
      "\t__start__ --> generate;\n",
      "\treflect --> generate;\n",
      "\tgenerate -.-> reflect;\n",
      "\tgenerate -.-> __end__;\n",
      "\tclassDef default fill:#f2f0ff,line-height:1.2\n",
      "\tclassDef first fill-opacity:0\n",
      "\tclassDef last fill:#bfb6fc\n",
      "\n",
      "          +-----------+            \n",
      "          | __start__ |            \n",
      "          +-----------+            \n",
      "                *                  \n",
      "                *                  \n",
      "                *                  \n",
      "          +----------+             \n",
      "          | generate |             \n",
      "          +----------+             \n",
      "          ...        ...           \n",
      "         .              .          \n",
      "       ..                ..        \n",
      "+---------+           +---------+  \n",
      "| reflect |           | __end__ |  \n",
      "+---------+           +---------+  \n"
     ]
    }
   ],
   "source": [
    "from typing import List, Sequence\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "from langchain_core.messages import BaseMessage, HumanMessage\n",
    "from langgraph.graph import END, MessageGraph\n",
    "\n",
    "\n",
    "REFLECT = \"reflect\"\n",
    "GENERATE = \"generate\"\n",
    "\n",
    "\n",
    "def generation_node(state: Sequence[BaseMessage]):\n",
    "    return generate_chain.invoke({\"messages\": state})\n",
    "\n",
    "\n",
    "def reflection_node(messages: Sequence[BaseMessage]) -> List[BaseMessage]:\n",
    "    res = reflect_chain.invoke({\"messages\": messages})\n",
    "    return [HumanMessage(content=res.content)]\n",
    "\n",
    "\n",
    "builder = MessageGraph()\n",
    "builder.add_node(GENERATE, generation_node)\n",
    "builder.add_node(REFLECT, reflection_node)\n",
    "builder.set_entry_point(GENERATE)\n",
    "\n",
    "\n",
    "def should_continue(state: List[BaseMessage]):\n",
    "    if len(state) > 6:\n",
    "        return END\n",
    "    return REFLECT\n",
    "\n",
    "\n",
    "builder.add_conditional_edges(GENERATE, should_continue)\n",
    "builder.add_edge(REFLECT, GENERATE)\n",
    "\n",
    "graph = builder.compile()\n",
    "print(graph.get_graph().draw_mermaid())\n",
    "graph.get_graph().print_ascii()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello LangGraph\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[HumanMessage(content='Make this tweet better:\"\\n                                @LangChainAI\\n        â€” newly Tool Calling feature is seriously underrated.\\n\\n        After a long wait, it\\'s  here- making the implementation of agents across different models with function calling - super easy.\\n\\n        Made a video covering their newest blog post\\n\\n                                ', additional_kwargs={}, response_metadata={}, id='8e4187cd-6dba-4a7a-b615-f725f690743a'),\n",
       " AIMessage(content='\"ðŸš€ Exciting news from @LangChainAI! Their new Tool Calling feature is a game-changer for implementing agents across various models with ease. Check out my latest video discussing their groundbreaking blog post! #AI #LangChainAI\"', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 50, 'prompt_tokens': 113, 'total_tokens': 163, 'completion_tokens_details': {'reasoning_tokens': 0}, 'prompt_tokens_details': {'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-e747a538-0d6f-4f5e-bc68-da0de5cc2916-0', usage_metadata={'input_tokens': 113, 'output_tokens': 50, 'total_tokens': 163, 'input_token_details': {'cache_read': 0}, 'output_token_details': {'reasoning': 0}}),\n",
       " HumanMessage(content='This revised tweet is more engaging and concise. It effectively conveys the excitement about the new Tool Calling feature, uses relevant hashtags to increase visibility, and invites followers to watch the video for more information. \\n\\nTo further improve the tweet, consider adding specific examples or benefits of the Tool Calling feature to highlight its significance. Including a call-to-action, such as \"Watch now\" or \"Learn more,\" can also prompt followers to engage with the content.\\n\\nIn terms of length, the revised tweet is well-structured and concise, making it easy to read and understand quickly. It strikes a good balance between providing information and maintaining brevity for better retention and engagement. \\n\\nOverall, this revised tweet is more likely to attract attention and drive interaction with the content shared.', additional_kwargs={}, response_metadata={}, id='e47d4468-aee7-4032-b5fc-2f87c9deddbd'),\n",
       " AIMessage(content='\"ðŸš€ Exciting news from @LangChainAI! Their new Tool Calling feature is a game-changer, simplifying agent implementation across models. Learn how this innovation is revolutionizing AI in my latest video discussing their blog post! #AI #LangChainAI #ToolCalling\"', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 58, 'prompt_tokens': 324, 'total_tokens': 382, 'completion_tokens_details': {'reasoning_tokens': 0}, 'prompt_tokens_details': {'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-34d8cb67-8fac-46d7-bd44-e62aca8d2c13-0', usage_metadata={'input_tokens': 324, 'output_tokens': 58, 'total_tokens': 382, 'input_token_details': {'cache_read': 0}, 'output_token_details': {'reasoning': 0}}),\n",
       " HumanMessage(content='This revised tweet effectively captures the excitement around @LangChainAI\\'s new Tool Calling feature and entices followers to engage with the content by watching the video. It uses relevant hashtags to increase visibility within the AI community and maintains a concise and engaging tone.\\n\\nTo make this tweet even more impactful, you could consider adding a specific example or anecdote about how the Tool Calling feature has benefited users or improved workflow efficiency. This would provide concrete evidence of its effectiveness and make the tweet more relatable to your audience.\\n\\nIncluding a call-to-action, such as \"Discover how Tool Calling can streamline your AI projects!\" or \"Watch now to see the Tool Calling feature in action,\" could encourage followers to take immediate action and engage with the content shared.\\n\\nOverall, this tweet is well-structured, engaging, and likely to generate interest among your followers. By incorporating specific examples and a compelling call-to-action, you can further enhance its effectiveness and drive increased interaction and viewership of your video content.', additional_kwargs={}, response_metadata={}, id='939d034d-2371-42e0-80b1-66afe0f4e6b4'),\n",
       " AIMessage(content='\"ðŸš€ Exciting news from @LangChainAI! The new Tool Calling feature is a game-changer, streamlining agent implementation across models. Watch my video to see how this innovation is revolutionizing AI! #AI #LangChainAI #ToolCalling Discover how Tool Calling can streamline your AI projects!\"', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 63, 'prompt_tokens': 586, 'total_tokens': 649, 'completion_tokens_details': {'reasoning_tokens': 0}, 'prompt_tokens_details': {'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-b16837e3-d0a0-40e2-b465-e07239588427-0', usage_metadata={'input_tokens': 586, 'output_tokens': 63, 'total_tokens': 649, 'input_token_details': {'cache_read': 0}, 'output_token_details': {'reasoning': 0}}),\n",
       " HumanMessage(content='\"ðŸš€ Exciting news from @LangChainAI! The new Tool Calling feature is a game-changer, simplifying agent implementation across models. Watch now to see how this innovation is revolutionizing AI! #AI #LangChainAI #ToolCalling Learn more about how Tool Calling can enhance your AI projects!\"', additional_kwargs={}, response_metadata={}, id='b2c5bf59-8070-4958-bd79-858c3f7229ff'),\n",
       " AIMessage(content='\"ðŸš€ Don\\'t miss out on the latest from @LangChainAI! The new Tool Calling feature is transforming agent implementation across models. Watch now to witness the AI revolution in action! #AI #LangChainAI #ToolCalling Dive deeper into how Tool Calling can supercharge your AI projects!\"', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 61, 'prompt_tokens': 721, 'total_tokens': 782, 'completion_tokens_details': {'reasoning_tokens': 0}, 'prompt_tokens_details': {'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-2e7ea480-2808-417f-aa9d-7e063bc06969-0', usage_metadata={'input_tokens': 721, 'output_tokens': 61, 'total_tokens': 782, 'input_token_details': {'cache_read': 0}, 'output_token_details': {'reasoning': 0}})]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Hello LangGraph\")\n",
    "inputs = HumanMessage(content=\"\"\"Make this tweet better:\"\n",
    "                                @LangChainAI\n",
    "        â€” newly Tool Calling feature is seriously underrated.\n",
    "\n",
    "        After a long wait, it's  here- making the implementation of agents across different models with function calling - super easy.\n",
    "\n",
    "        Made a video covering their newest blog post\n",
    "\n",
    "                                \"\"\")\n",
    "response = graph.invoke(inputs)\n",
    "response"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
